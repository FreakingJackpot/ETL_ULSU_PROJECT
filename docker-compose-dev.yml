version: '3.8'
x-web-config: &web-config
  DJANGO_SECRET_KEY: ${DJANGO_SECRET_KEY}
  DJANGO_DEBUG: ${DJANGO_DEBUG}
  DJANGO_ALLOWED_HOSTS: ${DJANGO_ALLOWED_HOSTS}
  DJANGO_CSRF_TRUSTED_ORIGINS: ${DJANGO_CSRF_TRUSTED_ORIGINS}
  DB_NAME: ${DB_NAME}
  DB_USER: ${DB_USER}
  DB_PASS: ${DB_PASS}
  DB_HOST: ${DB_HOST}
  DB_PORT: ${DB_PORT}

x-airflow-config: &airflow-config
  <<: *web-config
  AIRFLOW__CORE__DAGS_FOLDER: /dags
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow:${DB_AIRFLOW_PASS}@postgres:5432/airflow

  AIRFLOW__CORE__PARALLELISM: ${AIRFLOW_PARALLELISM}
  AIRFLOW__CORE__DAG_CONCURRENCY: ${AIRFLOW_DAG_CONCURRENCY}
  AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: ${AIRFLOW_MAX_ACTIVE_RUNS_PER_DAG}
  AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_CORE_LOAD_EXAMPLES}
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: ${AIRFLOW_CORE_LOAD_DEFAULT_CONNECTIONS}

  AIRFLOW__EMAIL__DEFAULT_EMAIL_ON_RETRY: ${AIRFLOW_EMAIL_DEFAULT_EMAIL_ON_RETRY}
  AIRFLOW__EMAIL__DEFAULT_EMAIL_ON_FAILURE: ${AIRFLOW_EMAIL_DEFAULT_EMAIL_ON_FAILURE}

  AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:${DB_AIRFLOW_PASS}@postgres/airflow
  AIRFLOW_DJANGO_PATH_TO_SETTINGS_PY: /app/covid_dashboard

  AIRFLOW__SCHEDULER__STATSD_ON: "True"
  AIRFLOW__SCHEDULER__STATSD_HOST: statsd-exporter
  AIRFLOW__SCHEDULER__STATSD_PORT: 8125
  AIRFLOW__SCHEDULER__STATSD_PREFIX: airflow

x-airflow-base: &airflow-base
  build:
    context: ./
    dockerfile: ./airflow/Dockerfile
  restart: always
  volumes:
    - ./airflow/dags:/dags
    - ./app:/app

services:
  postgres:
    image: postgres
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
      POSTGRES_DB: ${DB_NAME}
      PGUSER: ${DB_USER}
      POSTGRES_AIRFLOW_USER: airflow
      POSTGRES_AIRFLOW_PASSWORD: ${DB_AIRFLOW_PASS}
      POSTGRES_AIRFLOW_DB: airflow
    ports:
      - 5432:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data/
      - ./postgres:/docker-entrypoint-initdb.d

  external_postgres:
    image: freakingjackpot/etl_project:external_database
    container_name: external_postgres
    restart: always
    environment:
      POSTGRES_USER: ${EXTERNAL_DB_USER}
      POSTGRES_PASSWORD: ${EXTERNAL_DB_PASS}
      POSTGRES_DB: ${EXTERNAL_DB_NAME}
    ports:
      - 5433:5433
    command: -p 5433


  web:
    build:
      context: ./
      dockerfile: ./app/Dockerfile
    container_name: web
    restart: always
    command: python manage.py runserver 0.0.0.0:8000
    ports:
      - 8000:8000
    volumes:
      - ./app:/home/app/web/
    environment:
      <<: *web-config

    depends_on:
      - postgres

  redis:
    container_name: redis
    image: redis:7.2.3-alpine

  airflow:
    <<: *airflow-base
    container_name: airflow
    environment:
      <<: *airflow-config
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: ${AIRFLOW_SCHEDULER_DAG_DIR_LIST_INTERVAL}
      AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: ${AIRFLOW_SCHEDULER_CATCHUP_BY_DEFAULT}
      AIRFLOW__SCHEDULER__MAX_THREADS: ${AIRFLOW_SCHEDULER_MAX_THREADS}

      AIRFLOW__WEBSERVER__LOG_FETCH_TIMEOUT_SEC: ${AIRFLOW_WEBSERVER_LOG_FETCH_TIMEOUT_SEC}


    command: >
      -c "sleep 10 &&
           /entrypoint db init &&
          (/entrypoint webserver &) &&
          (/entrypoint celery flower &) &&
           /entrypoint scheduler"

    ports:
      # Celery Flower
      - 5555:5555
      # Airflow Webserver
      - 8081:8080

    depends_on:
      - postgres
      - redis

  worker:
    <<: *airflow-base
    container_name: airflow-worker
    environment:
      <<: *airflow-config

    command: -c " sleep 10 && /entrypoint celery worker"

    depends_on:
      - airflow
      - postgres
      - redis


volumes:
  postgres_data:
